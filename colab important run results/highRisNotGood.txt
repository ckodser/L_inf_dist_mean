Thu Jan 20 06:33:13 2022
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |
| N/A   60C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
result/CIFAR10_2lenght_True_rTrue_20exp4
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
manual_result_dir = result/CIFAR10_2
dataset = MNIST
model = MLPModel(depth=3,width=512,identity_val=10.0,scalar=True)
loss = mixture(lam0=0.05,lam_end=0.0002)
p_start = 8.0
p_end = 8.0
eps_train = 0.45
eps_test = 0.3
eps_smooth = 0
epochs = 0,0,2,15,17
decays = None
batch_size = 128
lr = 0.03
scalar_lr = 0.06
beta1 = 0.9
beta2 = 0.99
epsilon = 1e-10
start_epoch = 0
checkpoint = None
gpu = 0
dist_url = tcp://localhost:23456
world_size = 1
rank = 0
print_freq = 200
result_dir = result
filter_name =
seed = 2022
visualize = True
Compose(
    RandomCrop(size=(28, 28), padding=1)
    ToTensor()
    Normalize(mean=[0.1307], std=[0.3081])
)
MLPModel(
  (fc_dist): BoundSequential(
    (0): NormDist(
      in_features=784, out_features=512, bias=False
      (softMax): Softmax(dim=1)
      (mean_shift): MeanShift(512, affine=False)
    )
    (1): NormDist(
      in_features=512, out_features=512, bias=False
      (softMax): Softmax(dim=1)
      (mean_shift): MeanShift(512, affine=False)
    )
    (2): NormDist(
      in_features=512, out_features=10, bias=True
      (softMax): Softmax(dim=1)
    )
  )
)
number of params:  1338389
batch per epoch: 469
epoch = 0
 step=199 p=8.0  2.82 -0.42 Epoch: [0][200/469]   Time 0.305 (0.315)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   Loss 0.5426 (0.7522)   Acc 0.8125 (0.6930)   Certified (not fake) 0.3438 (0.1572)
 step=399 p=8.0  2.82 -0.42 Epoch: [0][400/469]   Time 0.310 (0.313)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   Loss 0.4187 (0.6098)   Acc 0.8750 (0.7629)   Certified (not fake) 0.5078 (0.3162)
 step=468 p=8.0  2.82 -0.42 Epoch 0:  train loss 0.5801   train acc 0.7728   worst(cert) 0.3546   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   time 146.65
Epoch 0:  test acc 0.8782  test cert acc  0.6845  time 7.66
Calculating metrics for L_infinity dist model on test set
Epoch 0:  clean acc 0.6334   certified acc 0.3733
epoch = 1
 step=199 p=8.0  2.82 -0.42 Epoch: [1][200/469]   Time 0.319 (0.309)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   Loss 0.3972 (0.3853)   Acc 0.8125 (0.8320)   Certified (not fake) 0.5703 (0.6085)
 step=399 p=8.0  2.82 -0.42 Epoch: [1][400/469]   Time 0.308 (0.307)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   Loss 0.3004 (0.3767)   Acc 0.8984 (0.8346)   Certified (not fake) 0.7266 (0.6202)
 step=468 p=8.0  2.82 -0.42 Epoch 1:  train loss 0.3754   train acc 0.8351   worst(cert) 0.6219   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   time 144.08
Epoch 1:  test acc 0.8823  test cert acc  0.7258  time 7.65
Calculating metrics for L_infinity dist model on test set
Epoch 1:  clean acc 0.6472   certified acc 0.4427
epoch = 2
 step=199 p=8.0  2.82 -0.42 Epoch: [2][200/469]   Time 0.311 (0.310)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0418   Loss 0.3119 (0.3560)   Acc 0.8203 (0.8404)   Certified (not fake) 0.7188 (0.6446)
 step=399 p=8.0  2.82 -0.42 Epoch: [2][400/469]   Time 0.303 (0.309)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0348   Loss 0.2788 (0.3487)   Acc 0.8828 (0.8417)   Certified (not fake) 0.7266 (0.6495)
 step=468 p=8.0  2.82 -0.42 Epoch 2:  train loss 0.3472   train acc 0.8417   worst(cert) 0.6504   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   time 144.79
Epoch 2:  test acc 0.8838  test cert acc  0.7350  time 7.71
Calculating metrics for L_infinity dist model on test set
Epoch 2:  clean acc 0.6476   certified acc 0.4216
epoch = 3
 step=199 p=8.0  2.82 -0.42 Epoch: [3][200/469]   Time 0.296 (0.310)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0273   Loss 0.3440 (0.3327)   Acc 0.8125 (0.8446)   Certified (not fake) 0.6797 (0.6593)
 step=399 p=8.0  2.82 -0.42 Epoch: [3][400/469]   Time 0.304 (0.308)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0228   Loss 0.2344 (0.3304)   Acc 0.8828 (0.8452)   Certified (not fake) 0.7656 (0.6599)
 step=468 p=8.0  2.82 -0.42 Epoch 3:  train loss 0.3302   train acc 0.8443   worst(cert) 0.6606   lr 0.0300   p 8.00   eps 1.4606   mix 0.0327   time 144.41
Epoch 3:  test acc 0.8880  test cert acc  0.7483  time 7.64
Calculating metrics for L_infinity dist model on test set
Epoch 3:  clean acc 0.6428   certified acc 0.4214
epoch = 4
 step=199 p=8.0  2.82 -0.42 Epoch: [4][200/469]   Time 0.316 (0.317)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0179   Loss 0.3457 (0.3247)   Acc 0.8047 (0.8432)   Certified (not fake) 0.6641 (0.6653)
 step=399 p=8.0  2.82 -0.42 Epoch: [4][400/469]   Time 0.420 (0.312)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0149   Loss 0.3067 (0.3207)   Acc 0.8359 (0.8451)   Certified (not fake) 0.6719 (0.6676)
 step=468 p=8.0  2.82 -0.42 Epoch 4:  train loss 0.3213   train acc 0.8438   worst(cert) 0.6668   lr 0.0300   p 8.00   eps 1.4606   mix 0.0214   time 146.34
Epoch 4:  test acc 0.8841  test cert acc  0.7425  time 7.64
Calculating metrics for L_infinity dist model on test set
Epoch 4:  clean acc 0.6408   certified acc 0.4133
epoch = 5
 step=15 p=8.0  2.82 -0.42