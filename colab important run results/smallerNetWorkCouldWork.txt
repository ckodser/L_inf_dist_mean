Thu Jan 20 06:49:18 2022
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |
| N/A   55C    P0    32W / 250W |      0MiB / 16280MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
result/CIFAR10_2lenght_True_rTrue_7exp4
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
manual_result_dir = result/CIFAR10_2
dataset = MNIST
model = MLPModel(depth=3,width=256,identity_val=10.0,scalar=True)
loss = mixture(lam0=0.05,lam_end=0.0002)
p_start = 8.0
p_end = 8.0
eps_train = 0.45
eps_test = 0.3
eps_smooth = 0
epochs = 0,0,2,15,17
decays = None
batch_size = 128
lr = 0.03
scalar_lr = 0.06
beta1 = 0.9
beta2 = 0.99
epsilon = 1e-10
start_epoch = 0
checkpoint = None
gpu = 0
dist_url = tcp://localhost:23456
world_size = 1
rank = 0
print_freq = 200
result_dir = result
filter_name =
seed = 2022
visualize = True
Compose(
    RandomCrop(size=(28, 28), padding=1)
    ToTensor()
    Normalize(mean=[0.1307], std=[0.3081])
)
MLPModel(
  (fc_dist): BoundSequential(
    (0): NormDist(
      in_features=784, out_features=256, bias=False
      (softMax): Softmax(dim=1)
      (mean_shift): MeanShift(256, affine=False)
    )
    (1): NormDist(
      in_features=256, out_features=256, bias=False
      (softMax): Softmax(dim=1)
      (mean_shift): MeanShift(256, affine=False)
    )
    (2): NormDist(
      in_features=256, out_features=10, bias=True
      (softMax): Softmax(dim=1)
    )
  )
)
number of params:  538133
batch per epoch: 469
epoch = 0
 step=199 p=8.0  2.82 -0.42 Epoch: [0][200/469]   Time 0.228 (0.241)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   Loss 0.6418 (0.8099)   Acc 0.8516 (0.7071)   Certified (not fake) 0.1875 (0.0959)
 step=399 p=8.0  2.82 -0.42 Epoch: [0][400/469]   Time 0.227 (0.237)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   Loss 0.6897 (0.7279)   Acc 0.8594 (0.7903)   Certified (not fake) 0.1484 (0.1394)
 step=468 p=8.0  2.82 -0.42 Epoch 0:  train loss 0.7108   train acc 0.8052   worst(cert) 0.1479   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   time 111.07
Epoch 0:  test acc 0.9205  test cert acc  0.2807  time 3.74
Calculating metrics for L_infinity dist model on test set
Epoch 0:  clean acc 0.4649   certified acc 0.1274
epoch = 1
 step=199 p=8.0  2.82 -0.42 Epoch: [1][200/469]   Time 0.227 (0.239)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   Loss 0.5007 (0.5298)   Acc 0.8750 (0.8746)   Certified (not fake) 0.3906 (0.3383)
 step=399 p=8.0  2.82 -0.42 Epoch: [1][400/469]   Time 0.231 (0.236)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   Loss 0.3706 (0.4860)   Acc 0.8828 (0.8634)   Certified (not fake) 0.5859 (0.4180)
 step=468 p=8.0  2.82 -0.42 Epoch 1:  train loss 0.4739   train acc 0.8618   worst(cert) 0.4385   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   time 110.23
Epoch 1:  test acc 0.9022  test cert acc  0.6327  time 3.71
Calculating metrics for L_infinity dist model on test set
Epoch 1:  clean acc 0.6950   certified acc 0.2037
epoch = 2
 step=199 p=8.0  2.82 -0.42 Epoch: [2][200/469]   Time 0.225 (0.234)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0418   Loss 0.3849 (0.3863)   Acc 0.8516 (0.8528)   Certified (not fake) 0.5938 (0.5838)
 step=399 p=8.0  2.82 -0.42 Epoch: [2][400/469]   Time 0.228 (0.232)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0348   Loss 0.3318 (0.3724)   Acc 0.8672 (0.8483)   Certified (not fake) 0.6406 (0.6107)
 step=468 p=8.0  2.82 -0.42 Epoch 2:  train loss 0.3691   train acc 0.8467   worst(cert) 0.6158   lr 0.0300   p 8.00   eps 1.4606   mix 0.0500   time 108.62
Epoch 2:  test acc 0.8853  test cert acc  0.7281  time 3.77
Calculating metrics for L_infinity dist model on test set
Epoch 2:  clean acc 0.8415   certified acc 0.4449
epoch = 3
 step=199 p=8.0  2.82 -0.42 Epoch: [3][200/469]   Time 0.231 (0.234)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0273   Loss 0.3234 (0.3447)   Acc 0.8828 (0.8419)   Certified (not fake) 0.6406 (0.6498)
 step=399 p=8.0  2.82 -0.42 Epoch: [3][400/469]   Time 0.226 (0.231)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0228   Loss 0.3313 (0.3421)   Acc 0.8750 (0.8402)   Certified (not fake) 0.6328 (0.6510)
 step=468 p=8.0  2.82 -0.42 Epoch 3:  train loss 0.3409   train acc 0.8403   worst(cert) 0.6518   lr 0.0300   p 8.00   eps 1.4606   mix 0.0327   time 108.23
Epoch 3:  test acc 0.8832  test cert acc  0.7434  time 3.70
Calculating metrics for L_infinity dist model on test set
Epoch 3:  clean acc 0.8196   certified acc 0.5604
epoch = 4
 step=199 p=8.0  2.82 -0.42 Epoch: [4][200/469]   Time 0.228 (0.231)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0179   Loss 0.2877 (0.3310)   Acc 0.8750 (0.8377)   Certified (not fake) 0.6953 (0.6584)
 step=399 p=8.0  2.82 -0.42 Epoch: [4][400/469]   Time 0.219 (0.230)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0149   Loss 0.3439 (0.3315)   Acc 0.8125 (0.8344)   Certified (not fake) 0.6328 (0.6576)
 step=468 p=8.0  2.82 -0.42 Epoch 4:  train loss 0.3311   train acc 0.8338   worst(cert) 0.6586   lr 0.0300   p 8.00   eps 1.4606   mix 0.0214   time 107.60
Epoch 4:  test acc 0.8770  test cert acc  0.7456  time 3.70
Calculating metrics for L_infinity dist model on test set
Epoch 4:  clean acc 0.6134   certified acc 0.3474
epoch = 5
 step=199 p=8.0  2.82 -0.42 Epoch: [5][200/469]   Time 0.241 (0.234)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0117   Loss 0.3080 (0.3267)   Acc 0.8438 (0.8311)   Certified (not fake) 0.6719 (0.6636)
 step=399 p=8.0  2.82 -0.42 Epoch: [5][400/469]   Time 0.241 (0.232)   lr 0.0300   p 8.00   eps 1.4606   mix 0.0097   Loss 0.3615 (0.3269)   Acc 0.8359 (0.8307)   Certified (not fake) 0.5938 (0.6626)
 step=468 p=8.0  2.82 -0.42 Epoch 5:  train loss 0.3269   train acc 0.8306   worst(cert) 0.6622   lr 0.0300   p 8.00   eps 1.4606   mix 0.0140   time 108.75
Epoch 5:  test acc 0.8774  test cert acc  0.7427  time 3.72
Calculating metrics for L_infinity dist model on test set
Epoch 5:  clean acc 0.6269   certified acc 0.3548
epoch = 6
 step=26 p=8.0 